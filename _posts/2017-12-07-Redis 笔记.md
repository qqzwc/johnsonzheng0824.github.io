---
layout: post
title: "Redis 笔记"
date: 2017-12-07
tag: Redis
---
### Redis 的安装看这篇：[Linux 服务器](https://johnsonzheng0824.github.io/Linux-%E6%9C%8D%E5%8A%A1%E5%99%A8/)

## Redis 是什么、特点、优势

Redis 是一个开源的使用 C 语言编写、开源、支持网络、可基于内存亦可持久化的日志型、高性能的 Key-Value 数据库，并提供多种语言的 API。

它通常被称为**数据结构服务器**，因为值（value）可以是 字符串 (String)、哈希 (Map)、 列表 (list)、集合 (sets) 和 有序集合 (sorted sets) 等类型。

Redis 与其他 key - value 缓存产品有以下三个特点：

*   Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。
*   Redis 不仅仅支持简单的 key-value 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。
*   Redis 支持数据的备份，即 master-slave 模式的数据备份。

Redis 优势

*   性能极高 – Redis 能读的速度是 110000 次 / s, 写的速度是 81000 次 / s 。
*   丰富的数据类型 – Redis 支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。
*   原子 – Redis 的所有操作都是原子性的，同时 Redis 还支持对几个操作全并后的原子性执行。
*   丰富的特性 – Redis 还支持 publish/subscribe, 通知, key 过期等等特性。

## Redis 启动后杂项基础知识讲解
![](/images/posts/redis/Snipaste_2018-05-15_22-48-47.png)

## 有关 key 的命令

| 序号 | Redis keys 命令及描述 |
| --- | --- |
| **1** | **keys \*<br>该命令用于获取 redis 中所有的 key** |
| **2** | **EXISTS key<br>检查给定 key 是否存在。** |
| **3** | **MOVE key db<br>将当前数据库的 key 移动到给定的数据库 db 当中。** |
| **4** | **EXPIRE key seconds<br>为给定 key 设置过期时间。** |
| **5** | **TTL key<br>以秒为单位，返回给定 key 的剩余生存时间 (TTL, time to live)。-1 表示永不过期，-2 表示已经过期** |
| **6** | **TYPE key<br>返回 key 所储存的值的类型。** |
| 7 | PEXPIRE key milliseconds<br>设置 key 的过期时间亿以毫秒计。 |
| 8 | PEXPIREAT key milliseconds-timestamp<br>设置 key 过期时间的时间戳 (unix timestamp) 以毫秒计 |
| 9 | KEYS pattern<br>查找所有符合给定模式 (pattern) 的 key 。例如 keys * 返回所有的 key |
| 10 | DUMP key<br>序列化给定 key ，并返回被序列化的值。 |
| 11 | PERSIST key<br>移除 key 的过期时间，key 将持久保持。 |
| 12 | PTTL key<br>以毫秒为单位返回 key 的剩余的过期时间。 |
| 13 | DEL key<br>该命令用于在 key 存在是删除 key。 |
| 14 | RANDOMKEY<br>从当前数据库中随机返回一个 key 。 |
| 15 | RENAME key newkey<br>修改 key 的名称 |
| 16 | RENAMENX key newkey<br>仅当 newkey 不存在时，将 key 改名为 newkey 。 |
| 17 | EXPIREAT key timestamp<br>EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳 (unix timestamp)。 |

## Redis 数据类型（重点）

Redis 支持五种数据类型：
- **String（字符串）**
- **Hash（哈希）**
- **List（列表）**
- Set（集合）
- Zset（sorted set：有序集合）

**String（字符串）**

*   是 Redis 最基本的数据类型，可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value
*   二进制安全的。意思是 redis 的 string 可以包含任何数据。比如 jpg 图片或者序列化的对象 
*   一个键最大能存储 **512MB**，即一个 redis 中字符串 value 最多可以是 **512MB**

![](/images/posts/redis/Snipaste_2018-05-16_19-43-49.png)

例子

```
127.0.0.1:6379> set var "String type"
OK
127.0.0.1:6379> get var
"String type"
```
说明：利用 set 给变量 var 赋值 “String type”；利用 get 获得变量 var 的值

**Hash（哈希）**

*   是一个键值对集合
*   是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象

> ps: 类似 java 里面的 Map<String, Object>

![](/images/posts/redis/Snipaste_2018-05-16_21-52-19.png)

hset,hget 例子

```
127.0.0.1:6379> hset set1 name jihite
(integer) 1
127.0.0.1:6379> hset set1 score 100
(integer) 1
127.0.0.1:6379> hget set1 name
"jihite"
```

hset&hget 一次只能往哈希结构里面插入一个键值对，如果插入多个可以用 hmset&hmget

hmset, hmget 例子

```
127.0.0.1:6379> HMSET student name jihite school henu
OK

127.0.0.1:6379> HMGET student name school
1) "jihite"
2) "henu"

127.0.0.1:6379> HGETALL student
1) "name"
2) "jihite"
3) "school"
4) "henu"
```

说明

student 是键值，每个 hash 可以存储 2<sup>32 - 1</sup> 键值对（40 多亿）

HMSET 用于建立 hash 对象，HGETALL 用于获取 hash 对象

hset v.s. hmset 操作对比

```
127.0.0.1:6379> hset set5 name1 jihite1 name2 jihite2 name3 jihite3
(error) ERR wrong number of arguments for 'hset' command
127.0.0.1:6379> hmset set5 name1 jihite1 name2 jihite2 name3 jihite3
OK
127.0.0.1:6379> hget set5 name1
"jihite1"
127.0.0.1:6379> hmget set5 name1
1) "jihite1"
127.0.0.1:6379> hmget set5 name1 name2
1) "jihite1"
2) "jihite2"
127.0.0.1:6379> hget set5 name1 name2
(error) ERR wrong number of arguments for 'hget' command
```


**List（列表）**

*   Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左部）或者尾部（右部）。
*   底层实际是个链表（LinkedList）

![](/images/posts/redis/Snipaste_2018-05-16_19-57-17.png)

性能总结
- 它是一个字符串的链表，left、right 都可以插入添加
- 如果键不存在，创建新的链表
- 如果键已存在，新增内容
- 如果值全移除，对应的键也就消失
- 链表的操作无论是头和尾效率都极高，但假如是对中间元素进行操作，效率就很惨淡了

例子

```
127.0.0.1:6379> lpush lvar 1
(integer) 1
127.0.0.1:6379> lpush lvar a
(integer) 2
127.0.0.1:6379> lpush lvar ab
(integer) 3

127.0.0.1:6379> lrange lvar 0 1
1) "ab"
2) "a"
127.0.0.1:6379> lrange lvar 0 10
1) "ab"
2) "a"
3) "1"
127.0.0.1:6379> lrange lvar 0 -1
1) "ab"
2) "a"
3) "1"
127.0.0.1:6379> lrange lvar 2 2
1) "1"
```


说明

lpush 往列表的前边插入（l 代表左）；lrange 后面的数字是范围（闭区间）ps: 0 -1 全取

列表最多可存储 2<sup>32 - 1</sup> 元素 (4294967295, 每个列表可存储 40 多亿)。

**Set(集合)**

*   Redis 的 Set 是 string 类型的无序集合。

*   Redis 的 Set 是通过哈希表（HashTable）实现的，所以添加，删除，查找的复杂度都是 O(1)

![](/images/posts/redis/Snipaste_2018-05-16_21-21-54.png)

例子

```
127.0.0.1:6379> sadd setvar redis
(integer) 1
127.0.0.1:6379> sadd setvar mongodb
(integer) 1
127.0.0.1:6379> sadd setvar mongodb
(integer) 0
127.0.0.1:6379> sadd setvar rabbitmq
(integer) 1
127.0.0.1:6379> smembers setvar
1) "rabbitmq"
2) "redis"
3) "mongodb"
```


说明

set 往集合中插入元素，smembers 列举出集合中的元素

成功插入返回 1；错误插入返回 0，例子中 mongodb 第二次插入时，因已经存在，故插入失败。

**Zset(sorted set：有序集合)**

*   zset 和 set 一样也是 String 类型的集合，且不允许元素重复

*   zset 和 set 不同的地方在于 zset 关联一个 double 类型的分数，redis 通过分数对集合中的元素排序（小到大）

*   zset 的元素是唯一的，但是分数（score）是可以重复的

![](/images/posts/redis/Snipaste_2018-05-16_22-06-03.png)

例子

```
127.0.0.1:6379> zadd zvar 1 redis
(integer) 1
127.0.0.1:6379> zadd zvar 1 redis
(integer) 0
127.0.0.1:6379> zadd zvar 2 redis
(integer) 0

127.0.0.1:6379> zadd zvar 2 mongo
(integer) 1
127.0.0.1:6379> zadd zvar 2 laji
(integer) 1
127.0.0.1:6379> ZRANGE zvar 0 -1
1) "laji"
2) "mongo"
3) "redis"
127.0.0.1:6379> ZRANGE zvar 0 -1 withscores
1) "laji"
2) "2"
3) "mongo"
4) "2"
5) "redis"
6) "1"

127.0.0.1:6379> ZRANGEBYSCORE zvar 0 -1
1) "laji"
2) "mongo"
3) "redis"
```

说明

成功插入返回 1，否则返回 0。插入已存在元素失败 -- 返回 0

分数为 float（可正、负、0）

## redis.conf 常见配置

**redis.conf 配置项说明如下：**

1. Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程<br>
  daemonize no
2. 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定<br>
  pidfile /var/run/redis.pid
3. 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字<br>
  port 6379
4. 绑定的主机地址<br>
  bind 127.0.0.1
5. 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能<br>
  timeout 300
6. 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose<br>
  loglevel verbose
7. 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null<br>
  logfile stdout
8. 设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id<br>
  databases 16
9. 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合<br>
  save \<seconds> \<changes><br>
  Redis默认配置文件中提供了三个条件：<br>
  save 900 1<br>
  save 300 10<br>
  save 60 10000<br>
  分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。
10. 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大<br>
  rdbcompression yes
11. 指定本地数据库文件名，默认值为dump.rdb<br>
  dbfilename dump.rdb
12. 指定本地数据库存放目录<br>
  dir ./
13. 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步<br>
  slaveof \<masterip> \<masterport>
14. 当master服务设置了密码保护时，slav服务连接master的密码<br>
  masterauth \<master-password>
15. 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭<br>
  requirepass foobared
16. 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息<br>
  maxclients 128
17. 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区<br>
  maxmemory \<bytes>
18. 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no<br>
  appendonly no
19. 指定更新日志文件名，默认为appendonly.aof<br>
   appendfilename appendonly.aof
20. 指定更新日志条件，共有3个可选值： <br>
  no：表示等操作系统进行数据缓存同步到磁盘（快） <br>
  always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） <br>
  everysec：表示每秒同步一次（折衷，默认值）<br>
  appendfsync everysec
21. 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制）<br>
   vm-enabled no
22. 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享<br>
   vm-swap-file /tmp/redis.swap
23. 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0<br>
   vm-max-memory 0
24. Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值<br>
   vm-page-size 32
25. 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。<br>
   vm-pages 134217728
26. 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4<br>
   vm-max-threads 4
27. 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启<br>
  glueoutputbuf yes
28. 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法<br>
  hash-max-zipmap-entries 64<br>
  hash-max-zipmap-value 512
29. 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）<br>
  activerehashing yes
30. 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件<br>
  include /path/to/local.conf
  
## redis 的持久化（重点）

- RDB(Redis DataBase)
- AOF(Append Only File)

### RDB(Redis DataBase)

**是什么**
- 在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里
- Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。

![](/images/posts/redis/Snipaste_2018-05-17_18-16-16.png)

说明

配置位置（默认的备份方式，备份到 dump.rdp 文件）：
指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合<br>
  save \<seconds> \<changes><br>
  Redis默认配置文件中提供了三个条件：<br>
  save 900 1<br>
  save 300 10<br>
  save 60 10000<br>
  分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。
  
例如：900秒（15分钟）内有1个更改，就会写入 dump.rdp 文件

**总结**

![](/images/posts/redis/Snipaste_2018-05-17_18-54-08.png)